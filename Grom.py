import streamlit as st
import pandas as pd
import numpy as np

st.set_page_config(page_title="Ğ—Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ğ½Ñ–ÑÑ‚ÑŒ Ñƒ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ…", layout="wide")

# ---- Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ´Ğ°Ğ½Ğ¸Ñ… ----
@st.cache_data
def load_csv(filelike):
    return pd.read_csv(filelike)

@st.cache_data
def load_csv_from_url(url: str):
    return pd.read_csv(url)

# ---- ĞŸĞ¾Ğ¿ĞµÑ€ĞµĞ´Ğ½Ñ Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ° ----
def preprocess(df, date_col='date', category_col='category', region_col='region'):
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    if date_col not in df.columns:
        raise KeyError(f"ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° '{date_col}' Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ñƒ CSV.")
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df = df.dropna(subset=[date_col])
    # ÑÑ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ– ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸, ÑĞºÑ‰Ğ¾ Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–
    if category_col not in df.columns:
        df[category_col] = 'Unknown'
    if region_col not in df.columns:
        df[region_col] = 'Unknown'
    df[category_col] = df[category_col].astype(str)
    df[region_col] = df[region_col].astype(str)
    df['month'] = df[date_col].dt.to_period('M').dt.to_timestamp()
    return df

def compute_crime_index(df, region_col='region'):
    agg = df.groupby(region_col).size().reset_index(name='total_crimes')
    minv = agg['total_crimes'].min()
    maxv = agg['total_crimes'].max()
    if pd.isna(minv) or pd.isna(maxv) or minv == maxv:
        agg['crime_index'] = 50.0
    else:
        agg['crime_index'] = (agg['total_crimes'] - minv) / (maxv - minv) * 100
    return agg

# ---- UI: Ğ´Ğ¶ĞµÑ€ĞµĞ»Ğ¾ Ğ´Ğ°Ğ½Ğ¸Ñ… ----
st.sidebar.header("Ğ”Ğ¶ĞµÑ€ĞµĞ»Ğ¾ Ğ´Ğ°Ğ½Ğ¸Ñ…")
source = st.sidebar.radio("ĞĞ±ĞµÑ€Ñ–Ñ‚ÑŒ:", ["ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–", "Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ CSV", "Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ Ğ· URL"])

if source == "ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–":
    # ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ñƒ
    rng = pd.date_range(end=pd.Timestamp.today(), periods=365)
    cats = ['ĞšÑ€Ğ°Ğ´Ñ–Ğ¶ĞºĞ°', 'Ğ¨Ğ°Ñ…Ñ€Ğ°Ğ¹ÑÑ‚Ğ²Ğ¾', 'ĞĞ°ÑĞ¸Ğ»ÑŒÑÑ‚Ğ²Ğ¾', 'ĞĞ°Ñ€ĞºĞ¾Ñ‚Ğ¸ĞºĞ¸']
    regions = ['ĞšĞ¸Ñ—Ğ²ÑÑŒĞºĞ°', 'Ğ›ÑŒĞ²Ñ–Ğ²ÑÑŒĞºĞ°', 'ĞĞ´ĞµÑÑŒĞºĞ°', 'Ğ¥Ğ°Ñ€ĞºÑ–Ğ²ÑÑŒĞºĞ°', 'Ğ”Ğ½Ñ–Ğ¿Ñ€Ğ¾Ğ¿ĞµÑ‚Ñ€Ğ¾Ğ²ÑÑŒĞºĞ°']
    np.random.seed(0)
    rows = []
    for d in rng:
        for r in regions:
            n = np.random.poisson(lam=1.8)
            for _ in range(n):
                rows.append({
                    'category': np.random.choice(cats),
                    'region': r,
                    'date': d + pd.to_timedelta(np.random.randint(0,24), unit='h')
                })
    df = pd.DataFrame(rows)

elif source == "Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ CSV":
    uploaded = st.sidebar.file_uploader("Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ñ‚Ğµ CSV (Ğ¼Ğ°Ñ” Ğ±ÑƒÑ‚Ğ¸ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· Ğ´Ğ°Ñ‚Ğ¾Ñ)", type=["csv"])
    if not uploaded:
        st.stop()
    df = load_csv(uploaded)

else:  # URL
    url = st.sidebar.text_input("URL Ğ´Ğ¾ CSV (Ğ¿Ñ€ÑĞ¼Ğµ Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ)")
    if not url:
        st.stop()
    df = load_csv_from_url(url)

# ---- ĞĞ°Ğ»Ğ°ÑˆÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ½Ğ°Ğ·Ğ² ÑÑ‚Ğ¾Ğ²Ğ¿Ñ†Ñ–Ğ² ----
st.sidebar.markdown("---")
st.sidebar.header("ĞĞ°Ğ»Ğ°ÑˆÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ ÑÑ‚Ğ¾Ğ²Ğ¿Ñ†Ñ–Ğ²")
date_col = st.sidebar.text_input("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· Ğ´Ğ°Ñ‚Ğ¾Ñ", "date")
category_col = st.sidebar.text_input("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ñ”Ñ", "category")
region_col = st.sidebar.text_input("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ¾Ğ¼", "region")

# ---- ĞĞ±Ñ€Ğ¾Ğ±ĞºĞ° Ğ´Ğ°Ğ½Ğ¸Ñ… Ñ– Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ ----
try:
    df = preprocess(df, date_col=date_col, category_col=category_col, region_col=region_col)
except Exception as e:
    st.error(f"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ¾Ğ±Ñ†Ñ–: {e}")
    st.stop()

st.title("ğŸ“Š Ğ—Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ğ½Ñ–ÑÑ‚ÑŒ Ñƒ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ… â€” Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´")
min_date = df[date_col].min().date()
max_date = df[date_col].max().date()
date_range = st.date_input("Ğ”Ñ–Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚", value=(min_date, max_date), min_value=min_date, max_value=max_date)

selected_cats = st.multiselect("ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ñ—", options=sorted(df[category_col].unique()), default=sorted(df[category_col].unique()))
selected_regs = st.multiselect("Ğ ĞµĞ³Ñ–Ğ¾Ğ½Ğ¸", options=sorted(df[region_col].unique()), default=sorted(df[region_col].unique()))

start_dt = pd.to_datetime(date_range[0])
end_dt = pd.to_datetime(date_range[1]) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)

mask = (
    (df[date_col] >= start_dt) &
    (df[date_col] <= end_dt) &
    (df[category_col].isin(selected_cats)) &
    (df[region_col].isin(selected_regs))
)
df_f = df[mask].copy()
st.write(f"ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑÑ–Ğ²: **{len(df_f)}** Ğ· {len(df)}")

# ---- Ğ”Ğ¸Ğ½Ğ°Ğ¼Ñ–ĞºĞ° (Ğ²Ğ±ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ñ– Ğ³Ñ€Ğ°Ñ„Ñ–ĞºĞ¸ streamlit) ----
st.subheader("Ğ”Ğ¸Ğ½Ğ°Ğ¼Ñ–ĞºĞ° Ğ·Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ñ–Ğ² (Ğ¿Ğ¾ Ğ¼Ñ–ÑÑÑ†ÑÑ…)")
trend = df_f.groupby(df_f['month']).size()
if len(trend) == 0:
    st.info("ĞĞµĞ¼Ğ°Ñ” Ğ´Ğ°Ğ½Ğ¸Ñ… Ñƒ Ğ²Ğ¸Ğ±Ñ€Ğ°Ğ½Ğ¾Ğ¼Ñƒ Ğ´Ñ–Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñ–.")
else:
    st.line_chart(trend)

st.subheader("Ğ Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–ÑÑ…")
cat_counts = df_f[category_col].value_counts()
st.bar_chart(cat_counts)

# ---- Ğ†Ğ½Ğ´ĞµĞºÑ ĞºÑ€Ğ¸Ğ¼Ñ–Ğ½Ğ¾Ğ³ĞµĞ½Ğ½Ğ¾ÑÑ‚Ñ– ----
st.subheader("Ğ†Ğ½Ğ´ĞµĞºÑ ĞºÑ€Ğ¸Ğ¼Ñ–Ğ½Ğ¾Ğ³ĞµĞ½Ğ½Ğ¾ÑÑ‚Ñ– Ğ¿Ğ¾ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ…")
index_df = compute_crime_index(df_f, region_col=region_col)
st.dataframe(index_df.sort_values('crime_index', ascending=False).reset_index(drop=True), use_container_width=True)

# ---- Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ Ğ· Ğ¿Ñ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ°Ğ¼Ğ¸ Ğ·Ğ°Ğ¿Ğ¸ÑÑ–Ğ² ----
st.subheader("ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ¸ Ğ·Ğ°Ğ¿Ğ¸ÑÑ–Ğ²")
st.dataframe(df_f.head(200), use_container_width=True)

# ---- Ğ•ĞºÑĞ¿Ğ¾Ñ€Ñ‚ ----
st.subheader("Ğ•ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ²Ñ–Ğ´Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ…")
csv = df_f.to_csv(index=False).encode('utf-8')
st.download_button("â¬‡ï¸ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ CSV", data=csv, file_name="filtered_crime_data.csv", mime="text/csv")

st.markdown("---")
st.caption("Ğ—Ğ³ĞµĞ½ĞµÑ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ· Ğ´Ğ¾Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ¾Ñ GPT Online â€” https://gptonline.ai/")
