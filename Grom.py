import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import folium
from streamlit_folium import st_folium
import requests
import json
import datetime

st.set_page_config(page_title="Ğ—Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ğ½Ñ–ÑÑ‚ÑŒ Ñƒ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ…", layout="wide")

# ---- ĞšĞµÑˆÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ´Ğ°Ğ½Ğ¸Ñ… ----
@st.cache_data
def load_csv(file):
    return pd.read_csv(file)

@st.cache_data
def load_csv_from_url(url: str):
    return pd.read_csv(url)

@st.cache_data
def load_geojson(url_or_path: str):
    """Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ GeoJSON Ğ±ĞµĞ· geopandas."""
    try:
        if str(url_or_path).startswith("http"):
            response = requests.get(url_or_path)
            response.raise_for_status()
            return response.json()
        else:
            with open(url_or_path, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception as e:
        st.error(f"ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ GeoJSON: {e}")
        return None

# ---- Ğ¤ÑƒĞ½ĞºÑ†Ñ–Ñ— ----
def preprocess(df, date_col='date', category_col='category', region_col='region'):
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df = df.dropna(subset=[date_col])
    df[category_col] = df[category_col].astype(str)
    df[region_col] = df[region_col].astype(str)
    df['month'] = df[date_col].dt.to_period('M').dt.to_timestamp()
    return df

def aggregate_by_region(df, region_col='region', date_col='month'):
    return (df.groupby([region_col, date_col])
              .size()
              .reset_index(name='count'))

def compute_crime_index(agg_df, population_df=None, region_col='region', count_col='count', scale=100000):
    df = agg_df.groupby(region_col)[count_col].sum().reset_index()
    df = df.rename(columns={count_col: 'total_crimes'})
    if population_df is not None:
        pop = population_df.rename(columns={pop.columns[0]:'region', pop.columns[1]:'population'})
        merged = df.merge(pop, on='region', how='left')
        merged['crime_rate'] = merged['total_crimes'] / merged['population'] * scale
        minv, maxv = merged['crime_rate'].min(), merged['crime_rate'].max()
        merged['crime_index'] = (merged['crime_rate'] - minv) / (maxv - minv) * 100
        return merged
    else:
        minv, maxv = df['total_crimes'].min(), df['total_crimes'].max()
        df['crime_index'] = (df['total_crimes'] - minv) / (maxv - minv) * 100
        return df

# ---- Ğ†Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ ----
st.sidebar.header("Ğ”Ğ¶ĞµÑ€ĞµĞ»Ğ¾ Ğ´Ğ°Ğ½Ğ¸Ñ…")
option = st.sidebar.radio("ĞĞ±ĞµÑ€Ñ–Ñ‚ÑŒ ÑĞ¿Ğ¾ÑÑ–Ğ± Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ:", ["ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–", "CSV-Ñ„Ğ°Ğ¹Ğ»", "URL"])

if option == "ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–":
    rng = pd.date_range(end=pd.Timestamp.today(), periods=365)
    categories = ['ĞšÑ€Ğ°Ğ´Ñ–Ğ¶ĞºĞ°', 'Ğ¨Ğ°Ñ…Ñ€Ğ°Ğ¹ÑÑ‚Ğ²Ğ¾', 'ĞĞ°ÑĞ¸Ğ»ÑŒÑÑ‚Ğ²Ğ¾', 'ĞĞ°Ñ€ĞºĞ¾Ñ‚Ğ¸ĞºĞ¸']
    regions = ['ĞšĞ¸Ñ—Ğ²', 'Ğ›ÑŒĞ²Ñ–Ğ²', 'ĞĞ´ĞµÑĞ°', 'Ğ¥Ğ°Ñ€ĞºÑ–Ğ²', 'Ğ”Ğ½Ñ–Ğ¿Ñ€Ğ¾']
    np.random.seed(42)
    data = []
    for d in rng:
        for r in regions:
            n = np.random.poisson(lam=2)
            for _ in range(n):
                data.append({
                    'category': np.random.choice(categories),
                    'region': r,
                    'date': d + pd.to_timedelta(np.random.randint(0, 24), unit='h')
                })
    df = pd.DataFrame(data)
elif option == "CSV-Ñ„Ğ°Ğ¹Ğ»":
    uploaded = st.sidebar.file_uploader("Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ñ‚Ğµ CSV", type="csv")
    if uploaded is None:
        st.stop()
    df = load_csv(uploaded)
else:
    url = st.sidebar.text_input("URL Ğ´Ğ¾ CSV")
    if not url:
        st.stop()
    df = load_csv_from_url(url)

# ---- ĞĞ±Ñ€Ğ¾Ğ±ĞºĞ° ----
date_col = st.sidebar.text_input("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· Ğ´Ğ°Ñ‚Ğ¾Ñ", "date")
cat_col = st.sidebar.text_input("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ñ”Ñ", "category")
reg_col = st.sidebar.text_input("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ¾Ğ¼", "region")

df = preprocess(df, date_col, cat_col, reg_col)

# ---- Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ ----
st.title("ğŸ“Š Ğ—Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ğ½Ñ–ÑÑ‚ÑŒ Ñƒ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ… Ğ£ĞºÑ€Ğ°Ñ—Ğ½Ğ¸")
st.markdown("ĞĞ½Ğ°Ğ»Ñ–Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ñ–Ğ· Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ”Ñ Ğ·Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ñ–Ğ² Ğ·Ğ° ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–ÑĞ¼Ğ¸, Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ğ¼Ğ¸ Ñ‚Ğ° Ñ‡Ğ°ÑĞ¾Ğ¼.")

min_d, max_d = df[date_col].min().date(), df[date_col].max().date()
sel_date = st.slider("Ğ’Ğ¸Ğ±ĞµÑ€Ñ–Ñ‚ÑŒ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´:", min_d, max_d, (min_d, max_d))
sel_cat = st.multiselect("ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ñ—:", sorted(df[cat_col].unique()), default=sorted(df[cat_col].unique()))
sel_reg = st.multiselect("Ğ ĞµĞ³Ñ–Ğ¾Ğ½Ğ¸:", sorted(df[reg_col].unique()), default=sorted(df[reg_col].unique()))

mask = (
    (df[date_col].dt.date >= sel_date[0]) &
    (df[date_col].dt.date <= sel_date[1]) &
    (df[cat_col].isin(sel_cat)) &
    (df[reg_col].isin(sel_reg))
)
df_f = df[mask]

st.write(f"ğŸ” Ğ’Ñ–Ğ´Ñ–Ğ±Ñ€Ğ°Ğ½Ğ¾ {len(df_f)} Ğ·Ğ°Ğ¿Ğ¸ÑÑ–Ğ² Ğ· {len(df)}")

# ---- Ğ”Ğ¸Ğ½Ğ°Ğ¼Ñ–ĞºĞ° Ğ·Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ñ–Ğ² ----
ts = df_f.groupby(pd.Grouper(key=date_col, freq='W'))[cat_col].count().reset_index(name='count')
fig_ts = px.line(ts, x=date_col, y='count', title="Ğ”Ğ¸Ğ½Ğ°Ğ¼Ñ–ĞºĞ° Ğ·Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ñ–Ğ² (Ñ‚Ğ¸Ğ¶Ğ½ĞµĞ²Ğ¾)")
st.plotly_chart(fig_ts, use_container_width=True)

ts_cat = df_f.groupby([pd.Grouper(key=date_col, freq='M'), cat_col]).size().reset_index(name='count')
fig_cat = px.area(ts_cat, x=date_col, y='count', color=cat_col, title="Ğ Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ·Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ñ–Ğ² Ğ·Ğ° ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–ÑĞ¼Ğ¸ (Ğ¼Ñ–ÑÑÑ†Ñ–)")
st.plotly_chart(fig_cat, use_container_width=True)

# ---- Ğ†Ğ½Ğ´ĞµĞºÑ ĞºÑ€Ğ¸Ğ¼Ñ–Ğ½Ğ¾Ğ³ĞµĞ½Ğ½Ğ¾ÑÑ‚Ñ– ----
agg = aggregate_by_region(df_f, reg_col, 'month')
index_df = compute_crime_index(agg, region_col=reg_col)
st.subheader("ğŸ“ˆ Ğ†Ğ½Ğ´ĞµĞºÑ ĞºÑ€Ğ¸Ğ¼Ñ–Ğ½Ğ¾Ğ³ĞµĞ½Ğ½Ğ¾ÑÑ‚Ñ– Ğ¿Ğ¾ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ…")
st.dataframe(index_df.sort_values("crime_index", ascending=False), use_container_width=True)

# ---- ĞšĞ°Ñ€Ñ‚Ğ° ----
geojson_url = st.sidebar.text_input("URL Ğ°Ğ±Ğ¾ ÑˆĞ»ÑÑ… Ğ´Ğ¾ GeoJSON (Ğ¾Ğ¿Ñ†Ñ–Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)")
if geojson_url:
    geojson_data = load_geojson(geojson_url)
    if geojson_data:
        m = folium.Map(location=[48.3794, 31.1656], zoom_start=6)
        folium.Choropleth(
            geo_data=geojson_data,
            data=index_df,
            columns=['region', 'crime_index'],
            key_on='feature.properties.name',  # Ğ·Ğ¼Ñ–Ğ½Ñ–Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğµ Ğ¿Ñ–Ğ´ Ğ²Ğ°Ñˆ GeoJSON
            fill_color='YlOrRd',
            fill_opacity=0.7,
            line_opacity=0.2,
            legend_name='Ğ†Ğ½Ğ´ĞµĞºÑ ĞºÑ€Ğ¸Ğ¼Ñ–Ğ½Ğ¾Ğ³ĞµĞ½Ğ½Ğ¾ÑÑ‚Ñ– (0â€“100)'
        ).add_to(m)
        st_folium(m, width=700, height=500)
else:
    fig_bar = px.bar(index_df, x='region', y='crime_index', color='crime_index',
                     color_continuous_scale='Reds', title="Ğ†Ğ½Ğ´ĞµĞºÑ ĞºÑ€Ğ¸Ğ¼Ñ–Ğ½Ğ¾Ğ³ĞµĞ½Ğ½Ğ¾ÑÑ‚Ñ– (Ğ±Ğ°Ñ€-Ğ³Ñ€Ğ°Ñ„Ñ–Ğº)")
    st.plotly_chart(fig_bar, use_container_width=True)

# ---- Ğ•ĞºÑĞ¿Ğ¾Ñ€Ñ‚ ----
csv = df_f.to_csv(index=False).encode('utf-8')
st.download_button("â¬‡ï¸ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ Ğ²Ñ–Ğ´Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ– Ğ´Ğ°Ğ½Ñ– CSV", data=csv, file_name="crime_filtered.csv", mime="text/csv")

st.markdown("---")
st.caption("Ğ¡Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¾ Ğ·Ğ° Ğ´Ğ¾Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ¾Ñ GPT Online â€” https://gptonline.ai/")
