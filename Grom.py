import streamlit as st
import pandas as pd
import numpy as np
import json
import requests
import io
import datetime

# Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ
import matplotlib.pyplot as plt

# ĞºĞ°Ñ€Ñ‚Ğ°
import folium
from streamlit_folium import st_folium

st.set_page_config(page_title="Ğ—Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ğ½Ñ–ÑÑ‚ÑŒ Ñƒ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ…", layout="wide")

# ---------- ĞšĞµÑˆĞ¾Ğ²Ğ°Ğ½Ñ– Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒĞ²Ğ°Ñ‡Ñ– ----------
@st.cache_data
def load_csv(filelike):
    return pd.read_csv(filelike)

@st.cache_data
def load_csv_from_url(url: str):
    return pd.read_csv(url)

@st.cache_data
def load_geojson(url_or_path: str):
    try:
        if str(url_or_path).startswith("http"):
            r = requests.get(url_or_path, timeout=10)
            r.raise_for_status()
            return r.json()
        else:
            with open(url_or_path, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception as e:
        st.error(f"ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ GeoJSON: {e}")
        return None

# ---------- Ğ”Ğ¾Ğ¿Ğ¾Ğ¼Ñ–Ğ¶Ğ½Ñ– Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ— ----------
def preprocess(df, date_col='date', category_col='category', region_col='region'):
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    # ÑĞºÑ‰Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· Ğ´Ğ°Ñ‚Ğ¾Ñ Ğ¼Ğ°Ñ” Ñ–Ğ½ÑˆÑƒ Ğ½Ğ°Ğ·Ğ²Ñƒ â€” ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡ Ğ¼Ğ¾Ğ¶Ğµ Ğ·Ğ¼Ñ–Ğ½Ğ¸Ñ‚Ğ¸ Ñƒ UI
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df = df.dropna(subset=[date_col])
    df[category_col] = df[category_col].astype(str)
    df[region_col] = df[region_col].astype(str)
    df['month'] = df[date_col].dt.to_period('M').dt.to_timestamp()
    return df

def aggregate_by_region(df, region_col='region', date_col='month'):
    return df.groupby([region_col, date_col]).size().reset_index(name='count')

def compute_crime_index(agg_df, population_df=None, region_col='region', count_col='count', scale=100000):
    total = agg_df.groupby(region_col)[count_col].sum().reset_index().rename(columns={count_col:'total_crimes'})
    if population_df is not None:
        pop = population_df.copy()
        pop.columns = [c.strip() for c in pop.columns]
        pop = pop.rename(columns={pop.columns[0]:'region', pop.columns[1]:'population'})
        merged = total.merge(pop, on='region', how='left')
        # ÑƒĞ½Ğ¸ĞºĞ°Ñ‚Ğ¸ Ğ´Ñ–Ğ»ĞµĞ½Ğ½Ñ Ğ½Ğ° 0
        merged['population'] = merged['population'].replace({0: np.nan})
        merged['crime_rate_per_100k'] = merged['total_crimes'] / merged['population'] * scale
        minv = merged['crime_rate_per_100k'].min()
        maxv = merged['crime_rate_per_100k'].max()
        if pd.isna(minv) or pd.isna(maxv) or minv == maxv:
            merged['crime_index'] = np.nan
        else:
            merged['crime_index'] = (merged['crime_rate_per_100k'] - minv) / (maxv - minv) * 100
        return merged
    else:
        minv = total['total_crimes'].min()
        maxv = total['total_crimes'].max()
        if minv == maxv:
            total['crime_index'] = 50.0
        else:
            total['crime_index'] = (total['total_crimes'] - minv) / (maxv - minv) * 100
        return total

def plot_time_series(df, date_col='date', freq='W'):
    ts = df.groupby(pd.Grouper(key=date_col, freq=freq)).size().reset_index(name='count')
    fig, ax = plt.subplots(figsize=(8, 3.5))
    ax.plot(ts[date_col], ts['count'], marker='o', linewidth=1)
    ax.set_title("Ğ”Ğ¸Ğ½Ğ°Ğ¼Ñ–ĞºĞ° Ğ·Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ñ–Ğ²")
    ax.set_xlabel("Ğ”Ğ°Ñ‚Ğ°")
    ax.set_ylabel("ĞšÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ")
    ax.grid(alpha=0.3)
    fig.tight_layout()
    return fig

def plot_category_stack(df, date_col='month', category_col='category'):
    pivot = df.groupby([date_col, category_col]).size().unstack(fill_value=0)
    fig, ax = plt.subplots(figsize=(8, 3.5))
    pivot.plot.area(ax=ax)
    ax.set_title("Ğ Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–ÑÑ… (Ğ¼Ñ–ÑÑÑ†ÑŒ)")
    ax.set_xlabel("ĞœÑ–ÑÑÑ†ÑŒ")
    ax.set_ylabel("ĞšÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ")
    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1))
    fig.tight_layout()
    return fig

# ---------- Ğ†Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ ----------
st.sidebar.header("Ğ”Ğ¶ĞµÑ€ĞµĞ»Ğ¾ Ğ´Ğ°Ğ½Ğ¸Ñ…")
source = st.sidebar.radio("ĞĞ±ĞµÑ€Ñ–Ñ‚ÑŒ:", ["ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–", "Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ CSV", "Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ Ğ· URL"])

if source == "ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–":
    # ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸ĞºĞ° Ğ´Ğ»Ñ ÑˆĞ²Ğ¸Ğ´ĞºĞ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ñƒ
    rng = pd.date_range(end=pd.Timestamp.today(), periods=365)
    cats = ['ĞšÑ€Ğ°Ğ´Ñ–Ğ¶ĞºĞ°', 'Ğ¨Ğ°Ñ…Ñ€Ğ°Ğ¹ÑÑ‚Ğ²Ğ¾', 'ĞĞ°ÑĞ¸Ğ»ÑŒÑÑ‚Ğ²Ğ¾', 'ĞĞ°Ñ€ĞºĞ¾Ñ‚Ğ¸ĞºĞ¸']
    regions = ['ĞšĞ¸Ñ—Ğ²ÑÑŒĞºĞ°','Ğ›ÑŒĞ²Ñ–Ğ²ÑÑŒĞºĞ°','ĞĞ´ĞµÑÑŒĞºĞ°','Ğ¥Ğ°Ñ€ĞºÑ–Ğ²ÑÑŒĞºĞ°','Ğ”Ğ½Ñ–Ğ¿Ñ€Ğ¾Ğ¿ĞµÑ‚Ñ€Ğ¾Ğ²ÑÑŒĞºĞ°']
    np.random.seed(1)
    rows = []
    for d in rng:
        for r in regions:
            n = np.random.poisson(lam=1.8)
            for _ in range(n):
                rows.append({'category': np.random.choice(cats),
                             'region': r,
                             'date': d + pd.to_timedelta(np.random.randint(0,24), unit='h')})
    df = pd.DataFrame(rows)
elif source == "Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ CSV":
    uploaded = st.sidebar.file_uploader("CSV Ñ„Ğ°Ğ¹Ğ» (category, region, date)", type=["csv"])
    if uploaded is None:
        st.stop()
    df = load_csv(uploaded)
else:
    url = st.sidebar.text_input("ĞŸÑ€ÑĞ¼Ğµ Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ Ğ½Ğ° CSV (URL)")
    if not url:
        st.stop()
    df = load_csv_from_url(url)

# Ğ½Ğ°Ğ·Ğ²Ğ¸ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº (ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡ Ğ¼Ğ¾Ğ¶Ğµ Ğ·Ğ¼Ñ–Ğ½Ğ¸Ñ‚Ğ¸)
st.sidebar.markdown("---")
st.sidebar.header("ĞĞ°Ğ»Ğ°ÑˆÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ ÑÑ‚Ğ¾Ğ²Ğ¿Ñ†Ñ–Ğ²")
date_col = st.sidebar.text_input("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· Ğ´Ğ°Ñ‚Ğ¾Ñ:", value='date')
category_col = st.sidebar.text_input("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ñ”Ñ:", value='category')
region_col = st.sidebar.text_input("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ· Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ¾Ğ¼:", value='region')

# Ğ¾Ğ¿Ñ†Ñ–Ğ¹Ğ½Ğ¾ Ğ½Ğ°ÑĞµĞ»ĞµĞ½Ğ½Ñ/geojson
st.sidebar.markdown("---")
pop_file = st.sidebar.file_uploader("ĞĞ¿Ñ†Ñ–Ğ¹Ğ½Ğ¾: CSV Ğ· Ğ½Ğ°ÑĞµĞ»ĞµĞ½Ğ½ÑĞ¼ (region,population)", type=["csv"])
geojson_source = st.sidebar.text_input("ĞĞ¿Ñ†Ñ–Ğ¹Ğ½Ğ¾: URL Ğ°Ğ±Ğ¾ ÑˆĞ»ÑÑ… Ğ´Ğ¾ GeoJSON (ĞºĞ¾Ğ½Ñ‚ÑƒÑ€Ğ¸ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ñ–Ğ²)")

# preprocess
try:
    df = preprocess(df, date_col=date_col, category_col=category_col, region_col=region_col)
except Exception as e:
    st.error(f"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ¸ Ğ´Ğ°Ğ½Ğ¸Ñ…: {e}")
    st.stop()

# Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸
st.title("ğŸ” Ğ—Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ğ½Ñ–ÑÑ‚ÑŒ Ñƒ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ… â€” Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´")
min_date = df[date_col].min().date()
max_date = df[date_col].max().date()
date_range = st.date_input("Ğ”Ñ–Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚:", value=(min_date, max_date), min_value=min_date, max_value=max_date)

selected_categories = st.multiselect("ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ñ—:", options=sorted(df[category_col].unique()), default=sorted(df[category_col].unique()))
selected_regions = st.multiselect("Ğ ĞµĞ³Ñ–Ğ¾Ğ½Ğ¸:", options=sorted(df[region_col].unique()), default=sorted(df[region_col].unique()))

start_dt = pd.to_datetime(date_range[0])
end_dt = pd.to_datetime(date_range[1]) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)

mask = (
    (df[date_col] >= start_dt) &
    (df[date_col] <= end_dt) &
    (df[category_col].isin(selected_categories)) &
    (df[region_col].isin(selected_regions))
)
df_f = df[mask].copy()
st.write(f"ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑÑ–Ğ²: **{len(df_f)}** Ğ· {len(df)}")

# Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ— â€” matplotlib
st.subheader("Ğ”Ğ¸Ğ½Ğ°Ğ¼Ñ–ĞºĞ° Ğ·Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ñ–Ğ²")
fig_ts = plot_time_series(df_f, date_col=date_col, freq='W')
st.pyplot(fig_ts)

st.subheader("Ğ Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ·Ğ° ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–ÑĞ¼Ğ¸")
fig_cat = plot_category_stack(df_f, date_col='month', category_col=category_col)
st.pyplot(fig_cat)

# Ñ–Ğ½Ğ´ĞµĞºÑ ĞºÑ€Ğ¸Ğ¼Ñ–Ğ½Ğ¾Ğ³ĞµĞ½Ğ½Ğ¾ÑÑ‚Ñ–
agg = aggregate_by_region(df_f, region_col, date_col='month')
pop_df = None
if pop_file is not None:
    try:
        pop_df = pd.read_csv(pop_file)
    except Exception as e:
        st.warning(f"ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚Ğ¸ population CSV: {e}")

index_df = compute_crime_index(agg, population_df=pop_df, region_col=region_col, count_col='count')
st.subheader("Ğ†Ğ½Ğ´ĞµĞºÑ ĞºÑ€Ğ¸Ğ¼Ñ–Ğ½Ğ¾Ğ³ĞµĞ½Ğ½Ğ¾ÑÑ‚Ñ– Ğ¿Ğ¾ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ…")
st.dataframe(index_df.sort_values('crime_index', ascending=False).reset_index(drop=True), use_container_width=True)

# ĞºĞ°Ñ€Ñ‚Ğ°
st.subheader("ĞšĞ°Ñ€Ñ‚Ğ° / Ñ…Ğ»Ğ¾Ñ€Ğ¾Ğ¿Ğ»ĞµÑ‚")
if geojson_source:
    geojson = load_geojson(geojson_source)
    if geojson:
        # ĞŸÑ€Ğ¾Ğ±ÑƒÑ”Ğ¼Ğ¾ Ğ²Ğ¸ÑĞ²Ğ¸Ñ‚Ğ¸ ÑĞºĞµ Ğ¿Ğ¾Ğ»Ğµ Ñƒ feature.properties Ğ¼Ñ–ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ½Ğ°Ğ·Ğ²Ñƒ (Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¸: name, NAME, region, region_name)
        # Ğ¯ĞºÑ‰Ğ¾ ĞºĞ»ÑÑ‡ Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ â€” ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡ Ğ¼Ğ°Ñ” Ğ²Ñ–Ğ´Ñ€ĞµĞ´Ğ°Ğ³ÑƒĞ²Ğ°Ñ‚Ğ¸ key_on Ñƒ ĞºĞ¾Ğ´Ñ– Ğ¿Ñ–Ğ´ ÑĞ²Ñ–Ğ¹ GeoJSON.
        example_props = geojson.get('features', [{}])[0].get('properties', {})
        prop_keys = list(example_props.keys())
        # Ğ—Ğ° Ğ·Ğ°Ğ¼Ğ¾Ğ²Ñ‡ÑƒĞ²Ğ°Ğ½Ğ½ÑĞ¼ Ğ¿Ñ–Ğ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼Ğ¾ 'name' ÑĞºÑ‰Ğ¾ Ñ”, Ñ–Ğ½Ğ°ĞºÑˆĞµ Ğ¿ĞµÑ€ÑˆĞ¸Ğ¹ ĞºĞ»ÑÑ‡
        key_name = 'name' if 'name' in prop_keys else (prop_keys[0] if prop_keys else None)
        if key_name is None:
            st.warning("ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ·Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ¾Ğ»Ğµ Ğ· Ğ½Ğ°Ğ·Ğ²Ğ¾Ñ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ñƒ Ñƒ GeoJSON (properties Ğ¿ÑƒÑÑ‚Ñ–).")
        else:
            m = folium.Map(location=[48.3794, 31.1656], zoom_start=6)
            # Ğ”Ğ»Ñ Choropleth Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ Ñƒ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ– [region, crime_index]
            if 'crime_index' in index_df.columns and region_col in index_df.columns:
                # ĞŸĞµÑ€ĞµĞºĞ¾Ğ½Ğ°Ñ”Ğ¼Ğ¾ÑÑ, Ñ‰Ğ¾ Ğ½Ğ°Ğ·Ğ²Ğ¸ Ğ·Ğ±Ñ–Ğ³Ğ°ÑÑ‚ÑŒÑÑ: ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡ Ğ¼Ğ°Ñ” Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ğ¿Ğ¾Ğ»Ğµ key_on
                try:
                    folium.Choropleth(
                        geo_data=geojson,
                        name='choropleth',
                        data=index_df,
                        columns=[region_col, 'crime_index'],
                        key_on=f'feature.properties.{key_name}',
                        fill_opacity=0.7,
                        line_opacity=0.2,
                        legend_name='Ğ†Ğ½Ğ´ĞµĞºÑ ĞºÑ€Ğ¸Ğ¼Ñ–Ğ½Ğ¾Ğ³ĞµĞ½Ğ½Ğ¾ÑÑ‚Ñ– (0-100)'
                    ).add_to(m)
                    st_folium(m, width=700, height=500)
                except Exception as e:
                    st.error(f"ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ¿Ğ¾Ğ±ÑƒĞ´ÑƒĞ²Ğ°Ñ‚Ğ¸ Ñ…Ğ»Ğ¾Ñ€Ğ¾Ğ¿Ğ»ĞµÑ‚: {e}. ĞœĞ¾Ğ¶Ğ»Ğ¸Ğ²Ğ¾, Ğ¿Ğ¾Ğ»Ğµ Ğ´Ğ»Ñ Ğ·Ğ²'ÑĞ·ĞºÑƒ Ğ½Ğ°Ğ·Ğ² Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ñ–Ğ² ('feature.properties.{key_name}') Ğ½Ğµ Ğ·Ğ±Ñ–Ğ³Ğ°Ñ”Ñ‚ÑŒÑÑ Ğ· ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¾Ñ region Ñƒ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ–.")
            else:
                st.info("ĞĞµĞ¼Ğ°Ñ” Ğ´Ğ°Ğ½Ğ¸Ñ… Ñ–Ğ½Ğ´ĞµĞºÑÑƒ Ğ´Ğ»Ñ ĞºĞ°Ñ€Ñ‚Ğ¸.")
else:
    # Ğ¯ĞºÑ‰Ğ¾ GeoJSON Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–Ğ¹ â€” Ğ¿Ğ¾ĞºĞ°Ğ·ÑƒÑ”Ğ¼Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñƒ ĞºÑ€ÑƒĞ³Ğ¾Ğ²Ñƒ ĞºĞ°Ñ€Ñ‚Ñƒ Ğ·Ğ° ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ°Ğ¼Ğ¸, ÑĞºÑ‰Ğ¾ Ğ²Ğ¾Ğ½Ğ¸ Ñ”
    if {'latitude','longitude'}.issubset(df_f.columns) or {'lat','lon'}.issubset(df_f.columns):
        lat_col = 'latitude' if 'latitude' in df_f.columns else 'lat'
        lon_col = 'longitude' if 'longitude' in df_f.columns else 'lon'
        pts = df_f.groupby([lat_col, lon_col]).size().reset_index(name='count')
        m = folium.Map(location=[pts[lat_col].mean(), pts[lon_col].mean()], zoom_start=6)
        for _, r in pts.iterrows():
            folium.CircleMarker(location=[r[lat_col], r[lon_col]],
                                radius=3 + np.log1p(r['count']),
                                popup=f"count: {r['count']}").add_to(m)
        st_folium(m, width=700, height=500)
    else:
        st.info("Ğ©Ğ¾Ğ± Ğ¿Ğ¾Ğ±Ğ°Ñ‡Ğ¸Ñ‚Ğ¸ ĞºĞ°Ñ€Ñ‚Ñƒ Ğ· ĞºĞ¾Ñ€Ğ´Ğ¾Ğ½Ğ°Ğ¼Ğ¸, Ğ´Ğ¾Ğ´Ğ°Ğ¹Ñ‚Ğµ GeoJSON Ñƒ Ğ±Ñ–Ñ‡Ğ½Ñ–Ğ¹ Ğ¿Ğ°Ğ½ĞµĞ»Ñ–, Ğ°Ğ±Ğ¾ Ğ´Ğ¾Ğ´Ğ°Ğ¹Ñ‚Ğµ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ¸ (latitude/longitude) Ñƒ CSV.")
        # Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚Ğ¸ Ğ±Ğ°Ñ€ Ğ¿Ğ¾ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ… (matplotlib)
        region_totals = agg.groupby(region_col)['count'].sum().reset_index().sort_values('count', ascending=False)
        fig, ax = plt.subplots(figsize=(8,3.5))
        ax.bar(region_totals[region_col], region_totals['count'])
        ax.set_title("Ğ—Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ğ° ĞºÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ Ğ·Ğ»Ğ¾Ñ‡Ğ¸Ğ½Ñ–Ğ² Ğ¿Ğ¾ Ñ€ĞµĞ³Ñ–Ğ¾Ğ½Ğ°Ñ…")
        ax.set_xlabel("Ğ ĞµĞ³Ñ–Ğ¾Ğ½")
        ax.set_ylabel("ĞšÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ")
        plt.xticks(rotation=45, ha='right')
        fig.tight_layout()
        st.pyplot(fig)

# ĞµĞºÑĞ¿Ğ¾Ñ€Ñ‚
st.subheader("Ğ•ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ²Ñ–Ğ´Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ…")
csv_bytes = df_f.to_csv(index=False).encode('utf-8')
st.download_button("Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ CSV", data=csv_bytes, file_name="filtered_crime_data.csv", mime="text/csv")

st.markdown("---")
st.caption("Ğ—Ğ³ĞµĞ½ĞµÑ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ· Ğ´Ğ¾Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ¾Ñ GPT Online â€” https://gptonline.ai/")
